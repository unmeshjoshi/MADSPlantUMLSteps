@startuml
!include ../../style.puml

title Distributed Query Execution Flow with Parquet

' [step1 {"name":"Query Planning"}]
actor "Data Analyst" as User
participant "Spark Driver" as Driver
participant "DAG Scheduler" as DAG
participant "Task Scheduler" as TS
participant "Catalog Service" as Catalog

User -> Driver: SQL Query\n"SELECT * FROM users WHERE age > 30"
activate Driver

Driver -> Catalog: Get table metadata
activate Catalog
Catalog --> Driver: Table location & schema
deactivate Catalog

Driver -> DAG: Create execution plan
activate DAG
DAG -> DAG: Parse query & optimize
DAG -> DAG: Create stages based on dependencies
DAG --> Driver: Execution plan with stages
deactivate DAG
' [/step1]

' [step2 {"name":"File Analysis"}]
group #LightBlue "File Analysis Phase"
Driver -> Driver: Read Parquet footer
Driver -> Driver: Analyze row group statistics
Driver -> Driver: Apply predicate pushdown
note right: Skip row groups where max_age ≤ 30
end
' [/step2]

' [step3 {"name":"Task Creation", "newPage":"true"}]
note top
**Task Creation and Distribution:**

1. Driver submits tasks to Task Scheduler
2. Task Scheduler creates one task per row group
3. Determines preferred locations based on data locality
4. Schedules tasks on available executors

**Task Distribution:**
• Task 1 (Row Group 1) → Executor 1
• Task 2 (Row Group 2) → Executor 2
• Task 3 (Row Group 3) → Executor 3
• Task 4 (Row Group 4) → Executor 1

Tasks distributed based on data locality and executor availability.
end note
' [/step3]

' [step4 {"name":"Parallel Execution"}]
note right of TS
**Parallel Execution Phase:**

1. Executors read row groups:
   • Executor 1 → Storage: Read Row Group 1
   • Executor 2 → Storage: Read Row Group 2
   • Executor 3 → Storage: Read Row Group 3

2. Each executor processes its data:
   • Apply filters (age > 30)
   • Project required columns
   • Prepare results for collection
end note
' [/step4]

' [step5 {"name":"Result Collection"}]
note right of Driver
**Result Collection Phase:**

1. Executors return filtered results:
   • Executor 1 → Driver: RG1 filtered data
   • Executor 2 → Driver: RG2 filtered data  
   • Executor 3 → Driver: RG3 filtered data

2. Driver processes results:
   • Combine results from all tasks
   • Apply final transformations
   • Return query results
end note
' [/step5]

note bottom
  **Optimization Benefits:**
  • Predicate pushdown eliminates unnecessary I/O
  • Parallel processing of independent row groups
  • Data locality reduces network traffic
  • Column pruning minimizes data transfer
end note

@enduml 
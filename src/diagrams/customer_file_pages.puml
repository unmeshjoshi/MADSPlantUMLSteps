@startuml

!include ../style.puml

title Customer Database File: Page-by-Page Layout

' [step1 {"name":"Database File Structure Overview"}]
note as overview
**Customer Database File (customers.dat)**
• File Size: 100MB (1,000,000 customers)
• Record Size: 100 bytes per customer
• OS Page Size: 4KB (4,096 bytes)
• Records per Page: 40 customers
• Total Pages: 25,000 pages
end note

rectangle "Physical File Layout" as layout #LightYellow {
  rectangle "File Header\n(Metadata)" as header_block #LightGray
}
' [/step1]

' [step2 {"name":"Beginning Pages: Sequential Customer Records"}]
rectangle "Beginning of File" as beginning #LightBlue {
  rectangle "Page 1" as page1 #LightGreen {
    rectangle "Customer IDs\n1 - 40" as customers1
  }
  rectangle "Page 2" as page2 #LightGreen {
    rectangle "Customer IDs\n41 - 80" as customers2
  }
  rectangle "Page 3" as page3 #LightGreen {
    rectangle "Customer IDs\n81 - 120" as customers3
  }
  rectangle "Page 4" as page4 #LightGreen {
    rectangle "Customer IDs\n121 - 160" as customers4
  }
}

note bottom of beginning
**Linear Search Problem:**
Without index, database must read sequentially
from Page 1 until target customer is found
end note
' [/step2]

' [step3 {"name":"Middle Section: Many Pages to Scan", "newPage":"true"}]
rectangle "File Middle Section" as middle #LightYellow {
  rectangle "Pages 5 - 1,624" as dots1 #LightGray {
    note bottom : Contains customers 161 - 64,960
  }
  
  rectangle "Page 1,625" as target_page #LightCoral {
    rectangle "Customer IDs\n64,961 - 65,000" as target_customers
    rectangle "Customer 65,000\n(Target Record)" as target #Gold
  }
  
  rectangle "Pages 1,626 - 25,000" as dots2 #LightGray {
    note bottom : Contains customers 65,001 - 1,000,000
  }
}

note bottom of middle
**Performance Impact:**
• Average search scans 12,500 pages (50% of file)
• Worst case: 25,000 pages (entire file)
• Each page = one disk I/O operation
• Total time: 1-3 seconds per query
end note
' [/step3]

' [step4 {"name":"Linear Search Process Visualization"}]
rectangle "Linear Search Process" as search #LightPink {
  rectangle "Read Page 1" as read1 #Orange {
    rectangle "Check: Customer 1-40\nNot found" as check1
  }
  rectangle "Read Page 2" as read2 #Orange {
    rectangle "Check: Customer 41-80\nNot found" as check2
  }
  rectangle "Read Page 3" as read3 #Orange {
    rectangle "Check: Customer 81-120\nNot found" as check3
  }
  rectangle "Continue..." as search_dots #LightGray
  rectangle "Read Page 1,625" as read_target #LightGreen {
    rectangle "Check: Customer 64,961-65,000\nFOUND Customer 65,000!" as found
  }
}

note bottom of search
**Linear Search Characteristics:**
• Must check pages in order: 1, 2, 3, ..., 1,625
• Cannot skip pages (no index guidance)
• Total I/O: 1,625 page reads for this query
• Time: ~1.6 seconds (assuming 1ms per page read)
end note
' [/step4]

' [step5 {"name":"Page Internal Structure Detail", "newPage":"true"}]
rectangle "Inside Page 1,625 (4KB)" as page_detail #LightBlue {
  rectangle "Page Header (96 bytes)" as page_header #LightGray {
    rectangle "Page ID: 1625\nRecord Count: 40\nNext Page: 1626" as header_info
  }
  
  rectangle "Customer Records (4000 bytes)" as records_section #LightYellow {
    rectangle "Record 1: Customer 64,961" as rec1 #LightGreen
    rectangle "Record 2: Customer 64,962" as rec2 #LightGreen
    rectangle "Record 39: Customer 64,999" as rec39 #LightGreen
    rectangle "Record 40: Customer 65,000" as rec40 #Gold
  }
}

note bottom of page_detail
**Page Structure:**
• Fixed 4KB size matches OS page size
• Header contains page metadata
• Records stored sequentially within page
• To find Customer 65,000: scan records 1-40 in this page
end note
' [/step5]

' [step6 {"name":"Why B+Tree Index Solves This Problem"}]
note as btree_solution
**The B+Tree Solution:**

**Problem with Linear Search:**
• Must read 1,625 pages to find Customer 65,000
• No way to know which page contains the target
• Performance degrades as file grows (O(n) complexity)

**How B+Tree Helps:**
• Index structure points directly to correct page
• Only 3 page reads: Root → Internal → Leaf
• Performance remains constant as file grows (O(log n))
• 99.8% reduction in I/O operations

**Key Insight:**
B+Tree transforms "find needle in haystack" 
into "follow roadmap to exact location"
end note
' [/step6]

' [step7 {"name":"File Layout vs Index Structure Comparison", "newPage":"true"}]
rectangle "File Layout (Linear)" as file_layout #LightCoral {
  rectangle "Pages 1-25,000\nSequential Access Required" as sequential
}

rectangle "B+Tree Index (Logarithmic)" as btree_layout #LightGreen {
  rectangle "Root Level" as root_level {
    rectangle "1 Page" as root_page
  }
  rectangle "Internal Level" as internal_level {
    rectangle "~100 Pages" as internal_pages
  }
  rectangle "Leaf Level" as leaf_level {
    rectangle "~1,000 Pages" as leaf_pages
  }
}

note bottom of file_layout
Must scan from beginning until target is found
end note

note bottom of btree_layout
**B+Tree Structure:**
• Height: 3 levels for 1M records
• Root: Always in memory (0 reads)
• Internal: 1 page read for navigation
• Leaf: 1 page read for data location
• Total: 2 page reads vs 1,625 page reads
end note
' [/step7]

' [step8 {"name":"Performance Impact Summary", "newPage":"true"}]
note as performance_summary
**Performance Comparison Summary:**

**Linear Search (No Index):**
• Pages to read: 1,625 (for Customer 65,000)
• Average pages: 12,500 (50% of file)
• Time per query: ~1.6 seconds
• Scalability: Gets worse as data grows

**B+Tree Search (With Index):**
• Pages to read: 2 (Internal + Leaf)
• Always: 2-3 pages regardless of file size
• Time per query: ~0.2 milliseconds
• Scalability: Stays constant as data grows

**Real-World Impact:**
• 812x fewer page reads for this specific query
• 8,000x better average case performance
• Enables sub-millisecond response times
• Supports millions of concurrent queries
end note
' [/step8]

@enduml 